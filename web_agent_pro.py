import json
import streamlit as st
from openai import OpenAI
from tavily import TavilyClient # ğŸ‘ˆ æ¢ä¸Šæ­£è§„å†› Tavilyï¼

st.set_page_config(page_title="å…¨èƒ½è€ç‹ (æ»¡è¡€è”ç½‘ç‰ˆ)", page_icon="ğŸŒ")
st.title("ğŸŒ å…¨èƒ½è€ç‹çš„ä¸“å± Web èŠå¤©å®¤ (Tavily å¼ºåŠ›é©±åŠ¨)")

client = OpenAI(
    api_key=st.secrets["API_KEY"], 
    base_url="https://dashscope.aliyuncs.com/compatible-mode/v1"
)

# åˆå§‹åŒ–ä¸“ä¸šçš„æœç´¢å®¢æˆ·ç«¯
tavily_client = TavilyClient(api_key=st.secrets["TAVILY_API_KEY"])

# ==========================================
# ğŸš¨ æ ¸å¿ƒæ¢è¡€ï¼šå¤§å‚çº§åˆ«çš„æœç´¢å·¥å…·
# ==========================================
def web_search(query):
    try:
        # ä½¿ç”¨ Tavily ä¸“é—¨ä¸º AI æä¾›çš„æœç´¢æ–¹æ³•
        response = tavily_client.search(query=query, search_depth="basic", max_results=3)
        # æå–çœŸå®ç½‘é¡µå†…å®¹ç»™è€ç‹
        results = [f"æ ‡é¢˜: {res['title']}\nå†…å®¹: {res['content']}" for res in response['results']]
        return "\n\n".join(results)
    except Exception as e:
        return f"æœç´¢å¤±è´¥ï¼Œç½‘ç»œå°å·®ï¼š{str(e)}"
tools = [{
    "type": "function",
    "function": {
        "name": "web_search",
        "description": "å½“ç”¨æˆ·è¯¢é—®å®æ—¶ä¿¡æ¯ã€æ–°é—»ã€ä¸çŸ¥é“çš„çŸ¥è¯†æ—¶ï¼Œå¿…é¡»è°ƒç”¨æ­¤å·¥å…·è¿›è¡Œè”ç½‘æœç´¢ã€‚",
        "parameters": {
            "type": "object",
            "properties": {
                "query": {
                    "type": "string",
                    "description": "æå–ç”¨æˆ·é—®é¢˜ä¸­çš„æ ¸å¿ƒæœç´¢å…³é”®è¯"
                }
            },
            "required": ["query"],
        },
    }
}]
# ==========================================

# 4. åˆå§‹åŒ–è®°å¿†
if "messages" not in st.session_state:
    st.session_state.messages = [
        {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªå¹½é»˜ã€å…¨èƒ½çš„èµ„æ·±AIåŠ©ç†è€ç‹ã€‚ä½ å¯ä»¥ä½¿ç”¨ web_search å·¥å…·è·å–æœ€æ–°èµ„è®¯ã€‚å›ç­”è¦è‡ªç„¶ï¼Œç»“åˆæœç´¢ç»“æœç»™å‡ºç­”æ¡ˆã€‚"}
    ]

# 5. æ¸²æŸ“å†å²è®°å½•
for msg in st.session_state.messages:
    if msg["role"] in ["user", "assistant"] and msg.get("content"):
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])

# 6. å¤„ç†æœ€æ–°è¾“å…¥
if user_input := st.chat_input("è€ƒè€ƒè€ç‹ï¼Œæ¯”å¦‚ï¼šä»Šå¤©Aè‚¡æ”¶ç›˜æ˜¯å¤šå°‘ç‚¹ï¼Ÿæˆ–è€… ä»Šå¤©çš„å¾®åšçƒ­æœæ˜¯ä»€ä¹ˆï¼Ÿ"):
    
    st.session_state.messages.append({"role": "user", "content": user_input})
    with st.chat_message("user"):
        st.markdown(user_input)

    with st.chat_message("assistant"):
        with st.spinner("è€ç‹æ­£åœ¨é£é€Ÿæ€è€ƒä¸­..."):
            response = client.chat.completions.create(
                model="qwen-coder-plus", 
                messages=st.session_state.messages,
                tools=tools
            )
            
            message = response.choices[0].message
            
            # åˆ¤æ–­æ˜¯å¦éœ€è¦è”ç½‘
            if message.tool_calls:
                tool_call = message.tool_calls[0]
                args = json.loads(tool_call.function.arguments)
                search_query = args.get("query")
                
                # ç½‘é¡µæç¤ºåŠ¨ç”»
                st.info(f"ğŸŒ è§¦å‘æŠ€èƒ½ï¼šè€ç‹æ­£åœ¨å…¨ç½‘æœç´¢ã€{search_query}ã€‘...")
                
                st.session_state.messages.append({
                    "role": "assistant",
                    "content": message.content or "", 
                    "tool_calls": [{
                        "id": tool_call.id,
                        "type": "function",
                        "function": {
                            "name": tool_call.function.name,
                            "arguments": tool_call.function.arguments
                        }
                    }]
                })
                
                # çœŸæ­£å»äº’è”ç½‘ä¸ŠæŸ¥èµ„æ–™ï¼
                search_result = web_search(search_query)
                
                st.session_state.messages.append({
                    "role": "tool",
                    "tool_call_id": tool_call.id,
                    "content": search_result
                })
                
                # æ‹¿ç€æœåˆ°çš„çœŸå®ç½‘é¡µæ•°æ®ï¼Œå†æ¬¡å‘¼å«å¤§æ¨¡å‹
                final_response = client.chat.completions.create(
                    model="qwen-coder-plus",
                    messages=st.session_state.messages
                )
                ai_reply = final_response.choices[0].message.content
                
                st.markdown(ai_reply)
                st.session_state.messages.append({"role": "assistant", "content": ai_reply})
                
            else:
                ai_reply = message.content
                st.markdown(ai_reply)
                st.session_state.messages.append({"role": "assistant", "content": ai_reply})