import streamlit as st
import os  # ğŸ‘ˆ æ–°å¢ï¼šç”¨äºä¿å­˜ä¸´æ—¶ä¸Šä¼ çš„æ–‡ä»¶
from langchain_openai import ChatOpenAI
from langchain_core.tools import tool
from langgraph.prebuilt import create_react_agent
from tavily import TavilyClient
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.embeddings import DashScopeEmbeddings
from langchain_community.vectorstores import FAISS

st.set_page_config(page_title="å®Œå…¨ä½“è€ç‹ (åŒè„‘é©±åŠ¨)", page_icon="ğŸ§ ")
st.title("ğŸ§  å®Œå…¨ä½“è€ç‹ (å…¬ç½‘ + ç§æœ‰çŸ¥è¯†åº“)")

# åˆå§‹åŒ–æ ¸å¿ƒå¼•æ“ (å¤§æ¨¡å‹ + æœç´¢å¼•æ“)
llm = ChatOpenAI(
    api_key=st.secrets["API_KEY"], 
    base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
    model="qwen-max"
) # ğŸ‘ˆ æ£€æŸ¥è¿™é‡Œï¼æ˜¯ä¸æ˜¯å°‘äº†è¿™ä¸ªåæ‹¬å·ï¼Ÿ

tavily_client = TavilyClient(api_key=st.secrets["TAVILY_API_KEY"]) # ğŸ‘ˆ è¿˜æœ‰è¿™é‡Œï¼Œæ˜¯ä¸æ˜¯æ‹¼å†™ä¸å®Œæ•´ï¼Ÿ

# ==========================================
# ğŸš¨ ç»ˆæè¿›åŒ–ï¼šç½‘é¡µä¾§è¾¹æ ä¸Šä¼ ç»„ä»¶
# ==========================================
with st.sidebar:
    st.header("ğŸ“‚ è€ç‹çš„è®°å¿†æ’æ§½")
    uploaded_file = st.file_uploader("è¯·å–‚ç»™è€ç‹ä¸€ä»½æ–°çš„ PDF ç§˜ç±", type=["pdf"])

# åŠ¨æ€è¯»å–å¹¶ç¼“å­˜ä¸Šä¼ çš„æ–‡ä»¶ï¼ˆæŠŠæ–‡ä»¶å­—èŠ‚æµä¼ è¿›æ¥ï¼Œåªè¦ä¼ äº†æ–°æ–‡ä»¶ï¼Œå°±ä¼šè‡ªåŠ¨åˆ·æ–°è„‘å­ï¼‰
@st.cache_resource(show_spinner=False)
def load_knowledge_base(file_bytes):
    with open("temp_upload.pdf", "wb") as f:
        f.write(file_bytes)
        
    # ğŸš¨ é­”æ³•è§‰é†’ï¼šå¼€å¯ extract_images=Trueï¼Œè€ç‹å°±ä¼šè‡ªåŠ¨è°ƒç”¨ OCR å¼•æ“å»â€œçœ‹â€å›¾ç‰‡é‡Œçš„å­—ï¼
    loader = PyPDFLoader("temp_upload.pdf", extract_images=True) 
    docs = loader.load()
    
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=20)
    splits = text_splitter.split_documents(docs)
    
    embeddings = DashScopeEmbeddings(
        dashscope_api_key=st.secrets["API_KEY"], 
        model="text-embedding-v3" 
    )
    return FAISS.from_documents(splits, embeddings)

# ä¿®æ”¹å‰é¢çš„ vectorstore åˆ¤æ–­é€»è¾‘
vectorstore = None
if uploaded_file is not None:
    with st.spinner("è€ç‹æ­£åœ¨ç–¯ç‹‚é€Ÿè¯» PDF..."):
        try:
            # å°è¯•æå–çœŸå®æ–‡ä»¶æ•°æ®å–‚ç»™å¤§æ¨¡å‹
            vectorstore = load_knowledge_base(uploaded_file.getvalue())
            st.sidebar.success("âœ… ç§˜ç±å¸æ”¶å®Œæ¯•ï¼å¯éšæ—¶æé—®ã€‚")
        except Exception as e:
            # å¦‚æœæŠ“åˆ°æŠ¥é”™ï¼ˆæ¯”å¦‚è¯»ä¸åˆ°æ–‡å­—å¯¼è‡´ IndexErrorï¼‰ï¼Œå°±æ‹¦æˆªä¸‹æ¥å¹¶æç¤ºç”¨æˆ·
            st.sidebar.error("âŒ å“å‘€ï¼Œè€ç‹æ²¡æ³•ä»è¿™ä¸ª PDF é‡Œæå–å‡ºæ–‡å­—ï¼å®ƒå¯èƒ½æ˜¯ä¸ªçº¯æ‰«æä»¶æˆ–è€…å›¾ç‰‡å“¦ï¼Œè¯·æ¢ä¸€ä»½èƒ½ç”¨é¼ æ ‡å¤åˆ¶æ–‡å­—çš„ PDF è¯•è¯•ï¼")
else:
    st.sidebar.info("ğŸ‘ˆ è¯·å…ˆä¸Šä¼  PDFï¼Œå¦åˆ™è€ç‹çš„ç§æœ‰è®°å¿†åº“æ˜¯ç©ºçš„å“¦ï¼")

# ==========================================
# ğŸ› ï¸ æŠ€èƒ½ 1ï¼šå…¬ç½‘æœç´¢ (ä¿æŒä¸å˜)
# ==========================================
@tool
def web_search(query: str) -> str:
    """å½“éœ€è¦æŸ¥è¯¢å®æ—¶ä¿¡æ¯ã€æ–°é—»ã€ä¸çŸ¥é“çš„å®¢è§‚çŸ¥è¯†æ—¶ï¼Œè°ƒç”¨æ­¤å·¥å…·å…¨ç½‘æœç´¢ã€‚"""
    try:
        response = tavily_client.search(query=query, search_depth="basic", max_results=2)
        return "\n\n".join([f"æ ‡é¢˜: {res['title']}\nå†…å®¹: {res['content']}" for res in response['results']])
    except Exception as e:
        return f"æœç´¢å¤±è´¥ï¼š{str(e)}"

# ==========================================
# ğŸ› ï¸ æŠ€èƒ½ 2ï¼šç§æœ‰çŸ¥è¯†åº“æœç´¢ (å¢åŠ åˆ¤ç©ºé€»è¾‘)
# ==========================================
@tool
def search_internal_doc(query: str) -> str:
    """å½“ç”¨æˆ·è¯¢é—®å…³äºä¸Šä¼ çš„PDFæ–‡ä»¶ã€å†…éƒ¨çŸ¥è¯†ã€å¤ä¹ èµ„æ–™æ—¶ï¼Œè°ƒç”¨æ­¤å·¥å…·ã€‚"""
    if vectorstore is None:
        return "è¯·ç¤¼è²Œåœ°å‘Šè¯‰ç”¨æˆ·ï¼šè€ç‹ç›®å‰æ²¡æœ‰æ‹¿åˆ° PDF æ–‡ä»¶ï¼Œè¯·å…ˆåœ¨ç½‘é¡µå·¦ä¾§ä¸Šä¼ ï¼"
    
    retriever = vectorstore.as_retriever()
    results = retriever.invoke(query)
    return "\n\n".join([res.page_content for res in results])

# å°†ä¸¤ä¸ªæŠ€èƒ½è£…è¿›å¤§è„‘
agent_executor = create_react_agent(llm, [web_search, search_internal_doc])


# ---------------- ä¸‹é¢æ˜¯ç½‘é¡µç•Œé¢çš„å¸¸è§„é€»è¾‘ ----------------
if "messages" not in st.session_state:
    st.session_state.messages = [{"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªå¹½é»˜çš„å…¨èƒ½AIåŠ©ç†è€ç‹ã€‚"}]

for msg in st.session_state.messages:
    if msg["role"] != "system":
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])

if user_input := st.chat_input("è¯•è¯•è¿æ‹›ï¼šä»Šå¤©çš„å¾®åšçƒ­æœæ˜¯ä»€ä¹ˆï¼Ÿé‚£è½¯ä»¶è®¾è®¡å¸ˆçš„å£è¯€å‘¢ï¼Ÿ"):
    st.session_state.messages.append({"role": "user", "content": user_input})
    with st.chat_message("user"):
        st.markdown(user_input)

    with st.chat_message("assistant"):
        with st.spinner("è€ç‹æ­£åœ¨å·¦å³è„‘åŒæ—¶è¿è½¬..."):
            response = agent_executor.invoke({"messages": st.session_state.messages})
            ai_reply = response["messages"][-1].content
            st.markdown(ai_reply)
            
    st.session_state.messages.append({"role": "assistant", "content": ai_reply})