import streamlit as st
from langchain_openai import ChatOpenAI
from langchain_core.tools import tool
from langgraph.prebuilt import create_react_agent
from tavily import TavilyClient

# 1. ç½‘é¡µé…ç½®
st.set_page_config(page_title="ç»ˆæè€ç‹ (LangChainç‰ˆ)", page_icon="ğŸ‘‘")
st.title("ğŸ‘‘ ç»ˆæè€ç‹ Web èŠå¤©å®¤ (å¤§å‚æ¡†æ¶é©±åŠ¨)")

# 2. åˆå§‹åŒ–æ ¸å¿ƒå¼•æ“ (å¤§æ¨¡å‹ + æœç´¢å¼•æ“)
llm = ChatOpenAI(
    api_key=st.secrets["API_KEY"], 
    base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
    model="qwen-coder-plus"
)
tavily_client = TavilyClient(api_key=st.secrets["TAVILY_API_KEY"])

# ==========================================
# ğŸš¨ ç»ˆæé­”æ³• 1ï¼šæç®€å·¥å…·å®šä¹‰
# ä¸éœ€è¦å†™ä»»ä½• JSONï¼ç›´æ¥ç”¨ @tool è£…é¥°å™¨ï¼
# ==========================================
@tool
def web_search(query: str) -> str:
    """å½“éœ€è¦æŸ¥è¯¢å®æ—¶ä¿¡æ¯ã€æ–°é—»ã€ä¸çŸ¥é“çš„çŸ¥è¯†æ—¶ï¼Œè°ƒç”¨æ­¤å·¥å…·å…¨ç½‘æœç´¢ã€‚"""
    try:
        response = tavily_client.search(query=query, search_depth="basic", max_results=3)
        return "\n\n".join([f"æ ‡é¢˜: {res['title']}\nå†…å®¹: {res['content']}" for res in response['results']])
    except Exception as e:
        return f"æœç´¢å¤±è´¥ï¼š{str(e)}"

# ==========================================
# ğŸš¨ ç»ˆæé­”æ³• 2ï¼šä¸€è¡Œä»£ç ç»„è£…æ™ºèƒ½ä½“ï¼
# ==========================================
agent_executor = create_react_agent(llm, [web_search])

# 3. Streamlit ç½‘é¡µè®°å¿†åˆå§‹åŒ–
if "messages" not in st.session_state:
    st.session_state.messages = [
        {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªå¹½é»˜ã€å…¨èƒ½çš„èµ„æ·±AIåŠ©ç†è€ç‹ã€‚ä½ æœ‰å®Œç¾çš„è®°å¿†åŠ›ã€‚"}
    ]

# 4. æ¸²æŸ“å†å²èŠå¤©æ°”æ³¡
for msg in st.session_state.messages:
    if msg["role"] != "system":
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])

# 5. æ ¸å¿ƒäº¤äº’é€»è¾‘
if user_input := st.chat_input("è·Ÿæ³¨å…¥äº† LangChain çµé­‚çš„è€ç‹èŠèŠå§ï¼æ¯”å¦‚ï¼šä»Šå¤©Aè‚¡æ”¶ç›˜ç‚¹æ•°ï¼Ÿ"):
    
    # æ˜¾ç¤ºç”¨æˆ·çš„è¾“å…¥
    st.session_state.messages.append({"role": "user", "content": user_input})
    with st.chat_message("user"):
        st.markdown(user_input)

    with st.chat_message("assistant"):
        with st.spinner("è€ç‹æ­£åœ¨é€šè¿‡ LangChain å¼•æ“é£é€Ÿæ€è€ƒå¹¶æ£€ç´¢å…¨ç½‘..."):
            
            # ==========================================
            # ğŸš¨ ç»ˆæé­”æ³• 3ï¼šå‘Šåˆ«ç¹ççš„å·¥å…·è°ƒç”¨å¾ªç¯ï¼
            # ç›´æ¥æŠŠæ•´ä¸ªèŠå¤©è®°å½•æ‰”ç»™ agent_executorï¼Œ
            # å®ƒä¼šè‡ªåŠ¨å¸®ä½ åˆ¤æ–­è¦ä¸è¦ç”¨å·¥å…·ã€è‡ªåŠ¨è°ƒç”¨ã€è‡ªåŠ¨æ€»ç»“ï¼
            # ==========================================
            response = agent_executor.invoke({"messages": st.session_state.messages})
            
            # ä» LangChain çš„è¿”å›ç»“æœä¸­ï¼Œæå–æœ€åä¸€å¥ AI è¯´çš„è¯
            ai_reply = response["messages"][-1].content
            
            # æ˜¾ç¤ºåœ¨ç½‘é¡µä¸Š
            st.markdown(ai_reply)
            
    # æŠŠå›ç­”å­˜å…¥è®°å¿†
    st.session_state.messages.append({"role": "assistant", "content": ai_reply})